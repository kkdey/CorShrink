\section{Methods and Materials}

As a simple version of a shrinkage estimator for a covariance matrix, one fits a convex combination of the empirical sample covariance matrix (S) along with a chosen target matrix T, which can be chosen to be an  identity matrix or constant correlation matrix. The mixing proportion $\delta$ in the convex combination $\delta T + (1- \delta) S$ is usually selected to maximize the expected accuracy of the shrunken estimator. In our approach, we shrink the correlations to $0$, implying the target matrix is the identity matrix. However, instead of a single target $T$, we assume multiple random targets $T_1$, $T_2$, $\cdots$, $T_k$, all centered around the same identity correlation matrix but each with different degrees of noise variation, usually increasing with $k$. The belief is that such an approach would adaptively decide on the amount of shrinkage without requiring to follow a Cross Validation approach. 

Let us denote the sample correlation matrix by $R = ((r_{ij}))_{i, j = 1,2, \cdots, P} $, $P$ being the number of features, calculated over $N$ data samples.

\begin{equation}
r_{ij} = \frac{s_{ij}}{\sqrt{s_{ii} s_{jj}}}   \hspace{1 in} s_{ij} = \frac{1}{n} \sum_{n=1}^{N} \left ( x_{ni} - \bar{x}_{i} \right ) \left ( x_{nj} - \bar{x}_{j} \right ) 
\end{equation}

where $s_{ij}$ is the sample covariance between the vectors $x_{*,i}$ and $x_{*,j}$.

We propose the following model

For any two features $i$ and $j$ with $ i < j$ , we define a binary size K latent variable vector $((Z_{ij:k}))$  where $Z_{ij:k}$ takes the values $1$ with probability $\pi_{k}$ and $0$ otherwise. 

%$$  Pr \left [ Z_{ij:k} = 1  \right ] = \pi_{k}    \hspace{1 in}  j < i $$

\begin{equation}
Pr \left [ Z | \pi \right ] = \prod_{i=1}^{P} \prod_{j < i} \prod_{k=1}^{K} \pi_{k}^{Z_{ij:k}}  
\end{equation}

We define  latent variables $\rho_{ij}$, such that

\begin{equation}
Pr \left ( \rho |  Z, \pi  \right )  = \prod_{i=1}^{P} \prod_{j < i} \prod_{k=1}^{K} \left [ N \left (\rho_{ij} : 0, \sigma^2_{k} \right ) \right ]^{Z_{ij:k}}  
\end{equation}

We assume Normal distribution for the $\rho$,

\begin{equation}
Pr \left (\hat{\rho}_{ij} | \rho \right ) = \prod_{i=1}^{P} \prod_{j < i } N \left (\hat{\rho}_{ij} | \rho_{ij}, s^2_n = \frac{1}{n-3} \right)  
\end{equation}

where $\hat{\rho}_{ij}$ are the Fisher's z-scores of the sample correlations $r_{ij}$ given by 

\begin{equation}
\hat{\rho}_{ij} = \frac{1}{2} \log \left ( \frac{1+r_{ij}}{1- r_{ij}} \right ) 
\end{equation}

The model implies that we shrink the $ \hat{\rho}_{ij}$ to $0$ but the amount of shrinkage is decided both by the number of independent samples $s^2_{n} = \frac{1}{n-3}$ and also by $\sigma_{k}$. 

We propose three different models depending on our assumptions on $\pi$ and $\sigma$. 

\begin{itemize}

\item \textit{CorShrink-ML}:  We choose a fixed grid of $\sigma$ values, selected such that it covers the span of the variation of the data well. Here we propose to use a similar grid (with minor adjustments) as suggested in Stephens 2016 \cite{Stephens2016} for modeling false discovery rates. We add a component with $\sigma_k=0$ that represents the null component of the prior. We fit the mixing proportions $\pi$ of the components using EM algorithm. 

\item \textit{CorShrink-VEM}: We use the same grid of $\sigma$ values as in the \textit{CorShrink-ML} model, but now we assume a Dirichlet prior on $\pi$, that puts a high weight on the null component and treats the other components equivalently. From performance comparisons on simulated data, we assumed the default Dirichlet prior to be $Dir(10, 1, ,1, \cdots, 1)$. 

\item \textit{CorShrink-VEM2}: We additionally assume the $\sigma$ values to be not fixed but to come from a Inverse-Gamma distribution. We assume $Inv-Gamma(\epsilon, \epsilon)$ distributions which are relatively non-informative in order to make the choice of $\sigma$ very flexible. For our applications in this paper, assume $\epsilon$ to be $0.01$.

\end{itemize}

The estimation of $\pi$ for the \textit{CorShrink-ML} model was performed using the \textbf{ashr} package due to Matthew Stephens \cite{Stephens2016}, which fits an EM algorithm. For the \textit{CorShrink-VEM} and \textit{CorShrink-VEM2}, we use Mean Field Variational EM models to estimate the model parameters. Variational methods are faster than MCMC methods as they often provide analytic updates to parameters thereby ensuring faster computation \cite{Beal2003} \cite{Beli2016}.

For \textit{CorShrink-VEM2} model where $\pi$ and $\sigma$ are both random, we first perform a change of variables 

$$ \xi_{k} = \sigma^2_{k} + \frac{1}{n-3} $$

Suppose the priors on $\pi$ and $\xi$ are 

$$ \pi \sim Dir \left ( \alpha_1, \alpha_2, \cdots, \alpha_{K} \right ) \hspace{1 in} \xi_{k} \sim Inv-Gamma(a, b) \;\; \forall \; k $$

and then define the mean field variational distribution on the latent variable $Z$ and the parameters $\pi$ and $\xi_1, \xi_2, \cdots, \xi_{K}$ as follows. 

$$  q(Z, \pi, \xi) = q(Z) q(\pi) \prod_{k=1}^{K} q(\xi_{k})   $$

Then the mean field distribution for $\pi$ is given by 

\begin{align}
\log q^{\star} (\pi)  & = E_{Z, \xi} \left [   \log p (\hat{\rho}, Z, \pi, \xi ) \right ]   \\
			    & = E_{Z} \left [ \sum_{k=1}^{K} \left (\alpha_{k} - 1\right) \log (\pi_k) + \sum_{i=1}^{J} \sum_{j < i} \sum_{k=1}^{K} z_{ij:k} \log (\pi_{k} ) \right ]  + const. \\
			    & = \sum_{k=1}^{K} \left [   \left (\alpha_{k} - 1\right)  + \sum_{i=1}^{J} \sum_{j < i}  \delta_{ij:k} \right]\log (\pi_{k})  \\
\end{align}

So the variational distribution for $\pi$ is of the form 

\begin{equation}
\pi \sim Dir \left (   \pi | \beta_1, \beta_2, \cdots, \beta_{K} \right ) \hspace{1 in}   \beta_{k} = \alpha_{k} + \sum_{i=1}^{J} \sum_{j < i} \delta_{ij:k} 
\end{equation}

The variational distribution of the latent variable $Z$ is obtained similarly

\begin{align}
\log q^{\star} (Z)  & = E_{\pi, \xi} \left [  \log p ( \hat{\rho}, Z, \pi, \xi ) \right ]   \\
			  & = E_{\pi, \xi} \left [   \log p(Z | \pi) +  \log p (\hat{\rho} | Z, \xi, \pi) \right ] \\
			  & = \sum_{i=1}^{P} \sum_{j < i}  \sum_{k=1}^{K} z_{ij:k} E_{\pi} \left (  \log (\pi_{k}) \right)  + \sum_{i=1}^{P} \sum_{j < i}  \sum_{k=1}^{K} z_{ij:k}  \left [ \frac{1}{2}  E_{\xi} \left [ \log \frac{1}{\xi_{k}} \right] - \frac{\hat{\rho}^2_{ij}}{2}  E_{\xi} \left [ \frac{1}{\xi} \right ] \right] \\
\end{align}

It can be shown that 

\begin{equation}
E_{\xi_{k}} \left [ \log \frac{1}{\xi_{k}} \right]  = - \log (\nu_{2k}) + \psi(\nu_{1k})   \hspace{0.4 in} E_{\xi_{k}} \left [ \frac{1}{\xi_{k}} \right ]  = \frac{\nu_{1k}}{\nu_{2k}} \hspace{0.4in} E_{\pi} \left (  \log (\pi_{k}) \right)  = \psi (\beta_{k}) - \psi (\sum_{l=1}^{K} \beta_{l} )
\end{equation}

where $\psi$ represents the digamma function. Using all of the above results, we get the following distribution of $Z$,

\begin{equation}
 q^{\star}(Z) = \prod_{i=1}^{P} \prod_{j < i} \prod_{k=1}^{K} \delta_{ij:k}^{Z_{ij:k}} \hspace{0.4in} 
\delta_{ij:k} \propto \exp \left (   \left \{ \psi (\beta_{k}) - \psi (\sum_{l=1}^{K} \beta_{l} ) + 0.5 \times ( \psi(\nu_{1k}) - \log (\nu_{2k}) ) -  \frac{\hat{\rho}^2_{ij}}{2} \frac{\nu_{1k}}{\nu_{2k}} \right \}  \right ) 
\end{equation}


For \textit{CorShrink-VEM} model, the $\sigma_{k}$ or $\xi_{k} = \sigma_{k} + \frac{1}{n-3}$ are fixed and the variational distribution is of the form 

\begin{equation}
q(Z, \pi) = q(Z) q(\pi) 
\end{equation}

The variational distribution is same as in \textit{CorShrink-VEM2} model, whereas the variational distribution of $Z$ can be achieved similarly as follows 

\begin{equation}
 q^{\star}(Z) = \prod_{i=1}^{P} \prod_{j < i} \prod_{k=1}^{K} \delta_{ij:k}^{Z_{ij:k}}
\hspace{0.4 in} \delta_{ij:k} \propto \exp \left (   \left \{ \psi (\beta_{k}) - \psi (\sum_{l=1}^{K} \beta_{l} ) + 0.5 \times \left ( \log \frac{1}{\xi_{k}} \right ) -  \frac{\hat{\rho}^2_{ij}}{2} \frac{1}{\xi_{k}} \right \}  \right ) 
\end{equation}

The \textit{CorShrink-VEM2} model is flexible in choice of $\pi$ and $\xi_{k}$'s, however it also has the problem of hitting a local maxima and the $\sigma_{k}$'s for multiple $k$'s to converge to same point. In order to counter that, we initialize the parameters first using the  \textit{CorShrink-VEM} model that assumes a fixed grid of well spread out $\xi_{k}$ values. 
Post the initialization, we apply the \textit{CorShrink-VEM2} model to the parameters. 

The other point to note is that actually the $\xi_{k}$'s are bounded below by $\frac{1}{n-3}$ which we ignore in defining an Inverse Gamma distribution on the $\xi$. This is a compromise for very small $n$ and we do therefore do not recommend the use of \textit{CorShrink-VEM2}  for very small $n$ values. Having said that, the initialization using \textit{CorShrink-VEM} fixes the $\xi_{k}$ initial values to be $ > \frac{1}{n-3}$ and we usually find that the final estimates would automatically adjust themselves to the lower bound and in case they violate, we forcibly set them to the lower bound value. 

In the next section, we discuss the applications of these three models on simulated and a real data drawn from single cell mouse embryo pre-implantation data.

%For the sake of technical advantage we assume an Inverse-Gamma distribution on $\xi_{k}$, and we choose the prior paramaters of the Inverse Gamma distribution such that it is very flat and allows for a wide range of possible values of $\xi_{k}$ and hence $\sigma_{k}$. It must be emphasized here that $\xi_{k}$'s are bounded below by $\frac{1}{n-3}$ while an Inverse gamma distribution has support from $0$ to $\infty$. However we consider $n$ to be moderately large, so $\frac{1}{n-3}$ would be a small number, which together with the flat shape of the inverse gamma prior will nullify the effect of the lower bound.



